// worker.js COMPLETO

// Importamos la librer칤a
import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';

// Configuraci칩n b치sica
env.allowLocalModels = false; 

// Variables globales
let transcriber = null;
let classifier = null;
let generator = null;
let visionModel = null;
let ragContext = ""; // Aqu칤 se guardar치 el texto del PDF

// ESCUCHAMOS MENSAJES DE LA INTERFAZ
self.addEventListener('message', async (event) => {
    // IMPORTANTE: A침adimos 'context' a la desestructuraci칩n para poder leerlo
    const { type, data, image, context } = event.data;

    try {
        switch (type) {
            case 'load':
                self.postMessage({ status: 'loading', message: 'Cargando Whisper...' });
                transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny');
                
                self.postMessage({ status: 'loading', message: 'Cargando Clasificador...' });
                classifier = await pipeline('zero-shot-classification', 'Xenova/mobilebert-uncased-mnli');

                self.postMessage({ status: 'loading', message: 'Cargando Generador...' });
                generator = await pipeline('text2text-generation', 'Xenova/LaMini-Flan-T5-248M');

                self.postMessage({ status: 'loading', message: 'Cargando Visi칩n...' });
                visionModel = await pipeline('image-to-text', 'Xenova/vit-gpt2-image-captioning');

                self.postMessage({ status: 'ready', message: '춰Sistema Completo Listo!' });
                break;

            case 'transcribe':
                if (!transcriber) return;
                const output = await transcriber(data);
                self.postMessage({ type: 'transcript', text: output.text });
                // Pasamos el texto a la l칩gica de los sombreros
                analyzeThinkingHats(output.text);
                break;

            case 'analyze-image':
                if (!visionModel || !generator) return;
                const visionOutput = await visionModel(image);
                const description = visionOutput[0].generated_text;
                const promptImg = `Give a short suggestion to improve a sketch of: ${description}`;
                const advice = await generator(promptImg, { max_new_tokens: 40 });

                self.postMessage({ 
                    type: 'hat-response', 
                    hat: 'multimodal', 
                    color: 'hat-purple',
                    text: `(Veo: ${description}) -> ${advice[0].generated_text}` 
                });
                break;

            // --- ESTE ES EL BLOQUE QUE TE FALTABA ---
            case 'update-context':
                // Guardamos el texto que viene desde main.js en la variable global
                ragContext = context;
                console.log("游늯 Worker: Contexto PDF actualizado. Longitud:", ragContext.length);
                break;
            // ----------------------------------------
        }
    } catch (error) {
        console.error(error);
        self.postMessage({ status: 'error', message: error.message });
    }
});

// FUNCI칍N L칍GICA DE LOS SOMBREROS (CON MEJORA DE B칔SQUEDA)
async function analyzeThinkingHats(text) {
    if (!classifier || !generator) return;

    // --- 1. AGENTE DE MEMORIA (RAG - Sombrero Blanco Potenciado) ---
    // Si hay PDF y pregunta, usamos el RAG como "Super Sombrero Blanco"
    if (ragContext && text.includes("?")) {
        console.log("游댍 Buscando en PDF...");
        const questionWords = text.toLowerCase().split(' ').filter(w => w.length > 3);
        let relevantChunk = ragContext.slice(0, 1500);

        for (let word of questionWords) {
            const index = ragContext.toLowerCase().indexOf(word);
            if (index !== -1) {
                const start = Math.max(0, index - 500);
                const end = Math.min(ragContext.length, index + 1000);
                relevantChunk = ragContext.slice(start, end);
                break;
            }
        }

        const promptRAG = `
        Instrucci칩n: Act칰a como un analista de datos (Sombrero Blanco). Responde a la pregunta usando SOLO el contexto.
        Contexto: "${relevantChunk}"
        Pregunta: "${text}"
        Respuesta (en espa침ol):`;
        
        const response = await generator(promptRAG, { max_new_tokens: 100 });
        
        self.postMessage({ 
            type: 'hat-response', 
            hat: 'Sombrero Blanco (Datos PDF)', 
            color: 'hat-white', 
            text: response[0].generated_text 
        });
        return; 
    }

    // --- 2. ORQUESTADOR (Clasificaci칩n Zero-Shot) ---
    // Definimos las etiquetas que corresponden a los 6 sombreros 
    const labels = [
        "cr칤tica y riesgos",       // Negro
        "ideas y creatividad",     // Verde
        "emociones y sentimientos",// Rojo
        "beneficios y optimismo",  // Amarillo
        "control y resumen",       // Azul
        "hechos y datos"           // Blanco (General)
    ];

    // El modelo decide cu치l encaja mejor
    const classification = await classifier(text, labels);
    const topLabel = classification.labels[0];
    
    // --- 3. EJECUCI칍N DE AGENTES (Prompts Din치micos)  ---
    let prompt = "";
    let hatColor = "";
    let hatName = "";

    switch (topLabel) {
        case "cr칤tica y riesgos": // SOMBRERO NEGRO
            prompt = `Analiza los riesgos o problemas de esta frase: "${text}". Responde en espa침ol brevemente.`;
            hatColor = "hat-black";
            hatName = "Sombrero Negro (Cr칤tico)";
            break;

        case "ideas y creatividad": // SOMBRERO VERDE
            prompt = `Prop칩n una idea alternativa o creativa relacionada con: "${text}". Responde en espa침ol.`;
            hatColor = "hat-green";
            hatName = "Sombrero Verde (Creativo)";
            break;

        case "emociones y sentimientos": // SOMBRERO ROJO
            prompt = `Analiza qu칠 emoci칩n transmite esta frase: "${text}". 쮼s frustraci칩n, alegr칤a, miedo? Responde en espa침ol.`;
            hatColor = "hat-red";
            hatName = "Sombrero Rojo (Emoci칩n)";
            break;

        case "beneficios y optimismo": // SOMBRERO AMARILLO
            prompt = `Menciona un beneficio positivo de esto: "${text}". Responde en espa침ol.`;
            hatColor = "hat-yellow";
            hatName = "Sombrero Amarillo (Optimista)";
            break;

        case "control y resumen": // SOMBRERO AZUL
            prompt = `Haz un resumen ejecutivo muy breve de: "${text}". Responde en espa침ol.`;
            hatColor = "hat-blue";
            hatName = "Sombrero Azul (Control)";
            break;

        default: // SOMBRERO BLANCO (Si no es PDF)
            prompt = `Extrae los hechos objetivos de: "${text}". Responde en espa침ol.`;
            hatColor = "hat-white";
            hatName = "Sombrero Blanco (Hechos)";
            break;
    }
    
    // Generamos la respuesta con el "Agente" seleccionado
    const response = await generator(prompt, { max_new_tokens: 60 });
    
    self.postMessage({ 
        type: 'hat-response', 
        hat: hatName, 
        color: hatColor,
        text: response[0].generated_text 
    });
}